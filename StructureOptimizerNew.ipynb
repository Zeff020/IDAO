{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import utils\n",
    "import scoring\n",
    "import numpy as np\n",
    "\n",
    "from skopt import Optimizer\n",
    "from skopt.learning.gaussian_process.kernels import Matern, RBF, WhiteKernel\n",
    "from skopt.learning import RandomForestRegressor\n",
    "from skopt.acquisition import gaussian_ei as acq_func\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing and structuring data ###\n",
    "\n",
    "DATA_PATH = \"./data/\"\n",
    "train, test = utils.load_data_csv(DATA_PATH, utils.SIMPLE_FEATURE_COLUMNS)\n",
    "\n",
    "PointResiduals,Angles,LineSlope, FirstPointResiduals, FourthPointResiduals = utils.kink(train)\n",
    "train['PointResiduals'] = pd.Series(PointResiduals, index=train.index)\n",
    "train['Angles'] = pd.Series(PointResiduals, index=train.index)\n",
    "train['LineSlope'] = pd.Series(PointResiduals, index=train.index)\n",
    "train['FirstPointResiduals'] = pd.Series(PointResiduals, index=train.index)\n",
    "train['FourthPointResiduals'] = pd.Series(PointResiduals, index=train.index)\n",
    "\n",
    "\n",
    "train_part, val_part = train_test_split(train, test_size=0.20, shuffle=True)\n",
    "x_train = train_part.loc[:, utils.SIMPLE_FEATURE_COLUMNS].values\n",
    "x_val   =  val_part.loc[:, utils.SIMPLE_FEATURE_COLUMNS].values\n",
    "y_train = train_part.loc[:, [\"label\"]].values\n",
    "y_val = val_part.loc[:, [\"label\"]].values\n",
    "#y_train_weight = train_part.loc[:, [\"weight\"]].values\n",
    "\n",
    "# turn labels into categorical classes\n",
    "classes = [0,1]\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=len(classes))\n",
    "y_val   = keras.utils.to_categorical(y_val,   num_classes=len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining utils ###\n",
    "\n",
    "# Rectified linear unit\n",
    "\n",
    "def relu(x):\n",
    "  return np.array([ (i>0) * abs(i) for i in x ])\n",
    "\n",
    "# plotting the bayesian optimizer\n",
    "\n",
    "def plot_bo(bo, suggestion=None, value=None):\n",
    "    a, b = bo.space.bounds[0]\n",
    "    \n",
    "    # getting the latest model\n",
    "    model = bo.models[-1]\n",
    "    \n",
    "    xs = np.linspace(a, b, num=100)\n",
    "    x_model = bo.space.transform(xs.reshape(-1, 1).tolist())\n",
    "    \n",
    "    mean, std = model.predict(x_model, return_std=True)\n",
    "    \n",
    "    plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(\n",
    "        np.array(bo.Xi)[:, 0],\n",
    "        np.array(bo.yi),\n",
    "        color='red',\n",
    "        label='observations'\n",
    "    )\n",
    "    if suggestion is not None:\n",
    "        plt.scatter([suggestion], value, color='blue', label='suggestion')\n",
    "    \n",
    "    plt.plot(xs, mean, color='green', label='model')\n",
    "    plt.fill_between(xs, mean - 1.96 * std, mean + 1.96 * std, alpha=0.1, color='green')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    acq = acq_func(x_model, model, np.min(bo.yi))\n",
    "    plt.plot(xs, acq, label='Expected Improvement')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# \n",
    "\n",
    "def cum_min(xs):\n",
    "    result = np.zeros_like(xs)\n",
    "    cmin = xs[0]\n",
    "    \n",
    "    result[0] = xs[0]\n",
    "    \n",
    "    for i in range(1, xs.shape[0]):\n",
    "        if cmin > xs[i]:\n",
    "            cmin = xs[i]\n",
    "\n",
    "        result[i] = cmin\n",
    "    \n",
    "    return result\n",
    "\n",
    "# plots progress of BO over time\n",
    "\n",
    "def plot_convergence(bo):\n",
    "    display.clear_output(wait=True)\n",
    "    values = np.array(bo.yi)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(cum_min(values), label='minimal discovered')\n",
    "    plt.scatter(np.arange(len(bo.yi)), bo.yi, label='observations')\n",
    "    plt.xlabel('step', fontsize=14)\n",
    "    plt.ylabel('loss', fontsize=14)\n",
    "    \n",
    "    plt.legend(loc='upper right', fontsize=18)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Prints best parameters\n",
    "    \n",
    "def print_best(bo):\n",
    "    best_result_index = np.argmin(bo.yi)\n",
    "    best_parameters = bo.Xi[best_result_index]\n",
    "\n",
    "    NodesInFirstDense, NodesInSecondDense, DropoutValue, INIT_LEARNINGRATE = best_parameters\n",
    "    \n",
    "    print(\n",
    "        'Best model:\\n Nodes in first dense layer= {0} \\n Nodes in second dense layer= {1} \\n learning rate= {2} \\n Dropout value= {3}'.format(\n",
    "            int(np.ceil(NodesInFirstDense)),\n",
    "            int(np.ceil(NodesInSecondDense)),\n",
    "            INIT_LEARNINGRATE,\n",
    "            DropoutValue\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Target function with as input optimizeable parameters ###\n",
    "\n",
    "def target_function1(params, X_train=x_train, y_train=y_train, X_score=x_val, y_score=y_val):\n",
    "    \n",
    "    # Optimized parameters\n",
    "    NodesInFirstDense, NodesInSecondDense, INIT_LEARNINGRATE, DropoutValue = params\n",
    "    \n",
    "    \n",
    "    # Making sure that the number of nodes are integers\n",
    "    NodesInFirstDense = int(np.ceil(NodesInFirstDense))\n",
    "    NodesInSecondDense = int(np.ceil(NodesInSecondDense))\n",
    "    \n",
    "    # Two parameters not optimized in this case, but can be optimized if needed\n",
    "    BATCH_SIZE = 16  # should be a factor of len(x_train) and len(x_val) etc.\n",
    "    EPOCHS = 3\n",
    "\n",
    "    assert len(y_train) == len(x_train), \"x_train and y_train not same length!\"\n",
    "    #assert len(y_train) % BATCH_SIZE == 0, \"batch size should be multiple of training size,{0}/{1}\".format(len(y_train),BATCH_SIZE)\n",
    "\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Activation, Dropout\n",
    "    from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "    K.clear_session()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(NodesInFirstDense, activation='relu', input_shape=( len( utils.SIMPLE_FEATURE_COLUMNS ), ))) #length = input vars\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(DropoutValue))\n",
    "    model.add(Dense(NodesInSecondDense , activation='relu'))\n",
    "    model.add(Dense( len(classes) )) # muon and 'other'\n",
    "    model.add(Activation(\"softmax\")) # output probabilities\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=keras.optimizers.adamax(lr=INIT_LEARNINGRATE),\n",
    "        metrics=['accuracy'] \n",
    "        )\n",
    "\n",
    "\n",
    "    model.fit(\n",
    "        x_train, y_train,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        epochs = EPOCHS,\n",
    "        validation_data = (x_val, y_val),\n",
    "        shuffle = True\n",
    "        )\n",
    "\n",
    "    #model.save_model(\"keras_basic_model.xgb\")\n",
    "\n",
    "\n",
    "    # score\n",
    "\n",
    "    validation_predictions = model.predict_proba(val_part.loc[:, utils.SIMPLE_FEATURE_COLUMNS].values)[:, 1]\n",
    "    result = scoring.rejection90(val_part.label.values, validation_predictions, sample_weight=val_part.weight.values)\n",
    "    print(result)\n",
    "    \n",
    "    return 1 - result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_function2(params, X_train=x_train, y_train=y_train, X_score=x_val, y_score=y_val):\n",
    "    \n",
    "    # Optimized parameters\n",
    "    NodesInFirstDense, NodesInSecondDense, NodesInThirdDense, INIT_LEARNINGRATE, DropoutValue  = params\n",
    "    \n",
    "    # Making sure that the number of nodes are integers\n",
    "    NodesInFirstDense = int(np.ceil(NodesInFirstDense))\n",
    "    NodesInSecondDense = int(np.ceil(NodesInSecondDense))\n",
    "    NodesInThirdDense = int(np.ceil(NodesInThirdDense))\n",
    "    \n",
    "    # Two parameters not optimized in this case, but can be optimized if needed\n",
    "    BATCH_SIZE = 16  # should be a factor of len(x_train) and len(x_val) etc.\n",
    "    EPOCHS = 3\n",
    "\n",
    "    assert len(y_train) == len(x_train), \"x_train and y_train not same length!\"\n",
    "    #assert len(y_train) % BATCH_SIZE == 0, \"batch size should be multiple of training size,{0}/{1}\".format(len(y_train),BATCH_SIZE)\n",
    "\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Activation, Dropout\n",
    "    from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "    K.clear_session()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(NodesInFirstDense, activation='relu', input_shape=( len( utils.SIMPLE_FEATURE_COLUMNS ), ))) #length = input vars\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(DropoutValue))\n",
    "    model.add(Dense(NodesInSecondDense , activation='relu'))\n",
    "    model.add(Dense(NodesInThirdDense )) # muon and 'other'\n",
    "    model.add(Dense( len(classes) )) # muon and 'other'\n",
    "    model.add(Activation(\"softmax\")) # output probabilities\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=keras.optimizers.adamax(lr=INIT_LEARNINGRATE),\n",
    "        metrics=['accuracy'] \n",
    "        )\n",
    "\n",
    "\n",
    "    model.fit(\n",
    "        x_train, y_train,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        epochs = EPOCHS,\n",
    "        validation_data = (x_val, y_val),\n",
    "        shuffle = True\n",
    "        )\n",
    "\n",
    "    #model.save_model(\"keras_basic_model.xgb\")\n",
    "\n",
    "\n",
    "    # score\n",
    "\n",
    "    validation_predictions = model.predict_proba(val_part.loc[:, utils.SIMPLE_FEATURE_COLUMNS].values)[:, 1]\n",
    "    result = scoring.rejection90(val_part.label.values, validation_predictions, sample_weight=val_part.weight.values)\n",
    "    print(result)\n",
    "    \n",
    "    return 1 - result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_function3(params, X_train=x_train, y_train=y_train, X_score=x_val, y_score=y_val):\n",
    "    \n",
    "    # Optimized parameters\n",
    "    NodesInFirstDense, NodesInSecondDense, NodesInThirdDense, NodesInFourthDense, INIT_LEARNINGRATE, DropoutValue = params\n",
    "    \n",
    "    # Making sure that the number of nodes are integers\n",
    "    NodesInFirstDense = int(np.ceil(NodesInFirstDense))\n",
    "    NodesInSecondDense = int(np.ceil(NodesInSecondDense))\n",
    "    NodesInThirdDense = int(np.ceil(NodesInThirdDense))\n",
    "    NodesInFourthDense = int(np.ceil(NodesInFourthDense))\n",
    "    \n",
    "    # Two parameters not optimized in this case, but can be optimized if needed\n",
    "    BATCH_SIZE = 16  # should be a factor of len(x_train) and len(x_val) etc.\n",
    "    EPOCHS = 3\n",
    "\n",
    "    assert len(y_train) == len(x_train), \"x_train and y_train not same length!\"\n",
    "    #assert len(y_train) % BATCH_SIZE == 0, \"batch size should be multiple of training size,{0}/{1}\".format(len(y_train),BATCH_SIZE)\n",
    "\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Activation, Dropout\n",
    "    from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "    K.clear_session()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(NodesInFirstDense, activation='relu', input_shape=( len( utils.SIMPLE_FEATURE_COLUMNS ), ))) #length = input vars\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(NodesInSecondDense , activation='relu'))\n",
    "    model.add(Dense(NodesInThirdDense )) # muon and 'other'\n",
    "    model.add(Dropout(DropoutValue))\n",
    "    model.add(Dense(NodesInFourthDense )) # muon and 'other'\n",
    "    model.add(Dense( len(classes) ))\n",
    "    model.add(Activation(\"softmax\")) # output probabilities\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=keras.optimizers.adamax(lr=INIT_LEARNINGRATE),\n",
    "        metrics=['accuracy'] \n",
    "        )\n",
    "\n",
    "\n",
    "    model.fit(\n",
    "        x_train, y_train,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        epochs = EPOCHS,\n",
    "        validation_data = (x_val, y_val),\n",
    "        shuffle = True\n",
    "        )\n",
    "\n",
    "    #model.save_model(\"keras_basic_model.xgb\")\n",
    "\n",
    "\n",
    "    # score\n",
    "\n",
    "    validation_predictions = model.predict_proba(val_part.loc[:, utils.SIMPLE_FEATURE_COLUMNS].values)[:, 1]\n",
    "    result = scoring.rejection90(val_part.label.values, validation_predictions, sample_weight=val_part.weight.values)\n",
    "    print(result)\n",
    "    \n",
    "    return 1 - result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_function4(params, X_train=x_train, y_train=y_train, X_score=x_val, y_score=y_val):\n",
    "    \n",
    "    # Optimized parameters\n",
    "    NodesInFirstDense, NodesInSecondDense, NodesInThirdDense, NodesInFourthDense,NodesInFifthDense, INIT_LEARNINGRATE, DropoutValue = params\n",
    "    \n",
    "    # Making sure that the number of nodes are integers\n",
    "    NodesInFirstDense = int(np.ceil(NodesInFirstDense))\n",
    "    NodesInSecondDense = int(np.ceil(NodesInSecondDense))\n",
    "    NodesInThirdDense = int(np.ceil(NodesInThirdDense))\n",
    "    NodesInFourthDense = int(np.ceil(NodesInFourthDense))\n",
    "    NodesInFifthDense = int(np.ceil(NodesInFifthDense))\n",
    "    \n",
    "    # Two parameters not optimized in this case, but can be optimized if needed\n",
    "    BATCH_SIZE = 16  # should be a factor of len(x_train) and len(x_val) etc.\n",
    "    EPOCHS = 3\n",
    "\n",
    "    assert len(y_train) == len(x_train), \"x_train and y_train not same length!\"\n",
    "    #assert len(y_train) % BATCH_SIZE == 0, \"batch size should be multiple of training size,{0}/{1}\".format(len(y_train),BATCH_SIZE)\n",
    "\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Activation, Dropout\n",
    "    from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "    K.clear_session()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(NodesInFirstDense, activation='relu', input_shape=( len( utils.SIMPLE_FEATURE_COLUMNS ), ))) #length = input vars\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(NodesInSecondDense , activation='relu'))\n",
    "    model.add(Dense(NodesInThirdDense )) # muon and 'other'\n",
    "    model.add(Dropout(DropoutValue))\n",
    "    model.add(Dense(NodesInFourthDense )) # muon and 'other'\n",
    "    model.add(Dense(NodesInFifthDense ))\n",
    "    model.add(Dense( len(classes) ))\n",
    "    model.add(Activation(\"softmax\")) # output probabilities\n",
    "\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=keras.optimizers.adamax(lr=INIT_LEARNINGRATE),\n",
    "        metrics=['accuracy'] \n",
    "        )\n",
    "\n",
    "\n",
    "    model.fit(\n",
    "        x_train, y_train,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        epochs = EPOCHS,\n",
    "        validation_data = (x_val, y_val),\n",
    "        shuffle = True\n",
    "        )\n",
    "\n",
    "    #model.save_model(\"keras_basic_model.xgb\")\n",
    "\n",
    "\n",
    "    # score\n",
    "\n",
    "    validation_predictions = model.predict_proba(val_part.loc[:, utils.SIMPLE_FEATURE_COLUMNS].values)[:, 1]\n",
    "    result = scoring.rejection90(val_part.label.values, validation_predictions, sample_weight=val_part.weight.values)\n",
    "    print(result)\n",
    "    \n",
    "    return 1 - result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_function_NoBatch(params, X_train=x_train, y_train=y_train, X_score=x_val, y_score=y_val):\n",
    "    \n",
    "    # Optimized parameters\n",
    "    NodesInFirstDense, NodesInSecondDense, INIT_LEARNINGRATE, DropoutValue = params\n",
    "    \n",
    "    # Making sure that the number of nodes are integers\n",
    "    NodesInFirstDense = int(np.ceil(NodesInFirstDense))\n",
    "    NodesInSecondDense = int(np.ceil(NodesInSecondDense))\n",
    "    \n",
    "    # Two parameters not optimized in this case, but can be optimized if needed\n",
    "    BATCH_SIZE = 16  # should be a factor of len(x_train) and len(x_val) etc.\n",
    "    EPOCHS = 3\n",
    "\n",
    "    assert len(y_train) == len(x_train), \"x_train and y_train not same length!\"\n",
    "    #assert len(y_train) % BATCH_SIZE == 0, \"batch size should be multiple of training size,{0}/{1}\".format(len(y_train),BATCH_SIZE)\n",
    "\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Activation, Dropout\n",
    "\n",
    "    K.clear_session()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(NodesInFirstDense, activation='relu', input_shape=( len( utils.SIMPLE_FEATURE_COLUMNS ), ))) #length = input vars\n",
    "    model.add(Dropout(DropoutValue))\n",
    "    model.add(Dense(NodesInSecondDense , activation='relu'))\n",
    "    model.add(Dense( len(classes) ))\n",
    "    model.add(Activation(\"softmax\")) # output probabilities\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=keras.optimizers.adamax(lr=INIT_LEARNINGRATE),\n",
    "        metrics=['accuracy'] \n",
    "        )\n",
    "\n",
    "\n",
    "    model.fit(\n",
    "        x_train, y_train,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        epochs = EPOCHS,\n",
    "        validation_data = (x_val, y_val),\n",
    "        shuffle = True\n",
    "        )\n",
    "\n",
    "    #model.save_model(\"keras_basic_model.xgb\")\n",
    "\n",
    "\n",
    "    # score\n",
    "\n",
    "    validation_predictions = model.predict_proba(val_part.loc[:, utils.SIMPLE_FEATURE_COLUMNS].values)[:, 1]\n",
    "    result = scoring.rejection90(val_part.label.values, validation_predictions, sample_weight=val_part.weight.values)\n",
    "    print(result)\n",
    "    \n",
    "    return 1 - result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting dimensions for optimizeable parameters ###\n",
    "\n",
    "dimensions_4 =[\n",
    "    # NodesInFirstDense\n",
    "    (4.0, 300.0),\n",
    "    \n",
    "    # NodesInSecondDense\n",
    "    (4.0, 300.0),\n",
    "    \n",
    "    # LOG_INIT_LEARNINGRATE\n",
    "    (1.0e-4, 1.0e-2),\n",
    "    \n",
    "    # DropoutValue\n",
    "    (0.0, 0.1)\n",
    "]\n",
    "\n",
    "dimensions_5 =[\n",
    "    # NodesInFirstDense\n",
    "    (4.0, 300.0),\n",
    "    \n",
    "    # NodesInSecondDense\n",
    "    (4.0, 300.0),\n",
    "    \n",
    "    # NodesInThirdDense\n",
    "    (4.0, 300.0),\n",
    "    \n",
    "    # LOG_INIT_LEARNINGRATE\n",
    "    (1.0e-4, 1.0e-2),\n",
    "    \n",
    "    # DropoutValue\n",
    "    (0.0, 0.1)\n",
    "]\n",
    "\n",
    "dimensions_6 =[\n",
    "    # NodesInFirstDense\n",
    "    (4.0, 300.0),\n",
    "    \n",
    "    # NodesInSecondDense\n",
    "    (4.0, 300.0),\n",
    "    \n",
    "    # NodesInThirdDense\n",
    "    (4.0, 300.0),\n",
    "    \n",
    "    # NodesInFourthDense\n",
    "    (4.0, 300.0),\n",
    "    \n",
    "    # LOG_INIT_LEARNINGRATE\n",
    "    (1.0e-4, 1.0e-2),\n",
    "    \n",
    "    # DropoutValue\n",
    "    (0.0, 0.1)\n",
    "]\n",
    "\n",
    "dimensions_7 =[\n",
    "    # NodesInFirstDense\n",
    "    (4.0, 300.0),\n",
    "    \n",
    "    # NodesInSecondDense\n",
    "    (4.0, 300.0),\n",
    "    \n",
    "    # NodesInThirdDense\n",
    "    (4.0, 300.0),\n",
    "    \n",
    "    # NodesInFourthDense\n",
    "    (4.0, 300.0),\n",
    "    \n",
    "    # NodesInFifthDense\n",
    "    (4.0, 300.0),\n",
    "    \n",
    "    # LOG_INIT_LEARNINGRATE\n",
    "    (1.0e-4, 1.0e-2),\n",
    "    \n",
    "    # DropoutValue\n",
    "    (0.0, 0.1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random forest regressor optimizer ###\n",
    "\n",
    "bo_rf_41 = Optimizer(\n",
    "    dimensions=dimensions_4,\n",
    "    base_estimator=RandomForestRegressor(\n",
    "        n_estimators=100, n_jobs=4, min_variance=1.0e-6\n",
    "    ),\n",
    "    n_initial_points=1,\n",
    "    acq_func='EI',   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "bo_rf_42 = Optimizer(\n",
    "    dimensions=dimensions_5,\n",
    "    base_estimator=RandomForestRegressor(\n",
    "        n_estimators=100, n_jobs=4, min_variance=1.0e-6\n",
    "    ),\n",
    "    n_initial_points=1,\n",
    "    acq_func='EI',   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "bo_rf_43 = Optimizer(\n",
    "    dimensions=dimensions_6,\n",
    "    base_estimator=RandomForestRegressor(\n",
    "        n_estimators=100, n_jobs=4, min_variance=1.0e-6\n",
    "    ),\n",
    "    n_initial_points=1,\n",
    "    acq_func='EI',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "bo_rf_44 = Optimizer(\n",
    "    dimensions=dimensions_7,\n",
    "    base_estimator=RandomForestRegressor(\n",
    "        n_estimators=100, n_jobs=4, min_variance=1.0e-6\n",
    "    ),\n",
    "    n_initial_points=1,\n",
    "    acq_func='EI',   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "OptimalParams1 = ([])\n",
    "OptimalParams2 = ([])\n",
    "OptimalParams3= ([])\n",
    "OptimalParams4= ([])\n",
    "OptimalParams_NoBatch = ([])\n",
    "\n",
    "OptimalScore1 = ([])\n",
    "OptimalScore2 = ([])\n",
    "OptimalScore3= ([])\n",
    "OptimalScore4= ([])\n",
    "OptimalScore_NoBatch = ([])\n",
    "\n",
    "# First network, original network, two dense layers\n",
    "for i in range(0,3):\n",
    "\n",
    "    bo_rf_41 = Optimizer(\n",
    "    dimensions=dimensions_4,\n",
    "    base_estimator=RandomForestRegressor(\n",
    "        n_estimators=100, n_jobs=4, min_variance=1.0e-6\n",
    "    ),\n",
    "    n_initial_points=10,\n",
    "    acq_func='EI',   \n",
    "    )\n",
    "\n",
    "    bo = bo_rf_41\n",
    "\n",
    "    for j in range(100):\n",
    "        x = bo.ask()\n",
    "        print(x)\n",
    "        f = target_function1(x) # Other inputs are automatically set\n",
    "\n",
    "        bo.tell(x, f)\n",
    "\n",
    "        plot_convergence(bo)\n",
    "\n",
    "    best_result_index = np.argmin(bo.yi)\n",
    "    best_parameters = bo.Xi[best_result_index]\n",
    "\n",
    "    OptimalParams1 = np.append(OptimalParams1,best_parameters, axis=0)\n",
    "    OptimalScore1 = np.append(OptimalScore1,bo.yi[np.argmin(bo.yi)])\n",
    "    \n",
    "    bo.yi[np.argmin(bo.yi)] = 1\n",
    "    \n",
    "    best_result_index = np.argmin(bo.yi)\n",
    "    best_parameters = bo.Xi[best_result_index]\n",
    "    \n",
    "    OptimalParams1 = np.append(OptimalParams1,best_parameters, axis=0)\n",
    "    OptimalScore1 = np.append(OptimalScore1,bo.yi[np.argmin(bo.yi)])\n",
    "    \n",
    "    bo.yi[np.argmin(bo.yi)] = 1\n",
    "    \n",
    "    best_result_index = np.argmin(bo.yi)\n",
    "    best_parameters = bo.Xi[best_result_index]\n",
    "    \n",
    "    OptimalParams1 = np.append(OptimalParams1,best_parameters, axis=0)\n",
    "    OptimalScore1 = np.append(OptimalScore1,bo.yi[np.argmin(bo.yi)])\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "# Second network, three dense layers\n",
    "for i in range(0,3):\n",
    "\n",
    "    bo_rf_42 = Optimizer(\n",
    "    dimensions=dimensions_5,\n",
    "    base_estimator=RandomForestRegressor(\n",
    "        n_estimators=100, n_jobs=4, min_variance=1.0e-6\n",
    "    ),\n",
    "    n_initial_points=10,\n",
    "    acq_func='EI',   \n",
    "    )\n",
    "\n",
    "    bo = bo_rf_42\n",
    "\n",
    "    for j in range(150):\n",
    "        x = bo.ask()\n",
    "        print(x)\n",
    "        f = target_function2(x) # Other inputs are automatically set\n",
    "\n",
    "        bo.tell(x, f)\n",
    "\n",
    "        plot_convergence(bo)\n",
    "\n",
    "    best_result_index = np.argmin(bo.yi)\n",
    "    best_parameters = bo.Xi[best_result_index]\n",
    "\n",
    "\n",
    "    OptimalParams2 = np.append(OptimalParams2, best_parameters, axis=0)\n",
    "    OptimalScore2 = np.append(OptimalScore2,bo.yi[np.argmin(bo.yi)])\n",
    "    \n",
    "    bo.yi[np.argmin(bo.yi)] = 1\n",
    "    \n",
    "    best_result_index = np.argmin(bo.yi)\n",
    "    best_parameters = bo.Xi[best_result_index]\n",
    "    \n",
    "    OptimalParams2 = np.append(OptimalParams2,best_parameters, axis=0)\n",
    "    OptimalScore2 = np.append(OptimalScore2,bo.yi[np.argmin(bo.yi)])\n",
    "    \n",
    "    bo.yi[np.argmin(bo.yi)] = 1\n",
    "    \n",
    "    best_result_index = np.argmin(bo.yi)\n",
    "    best_parameters = bo.Xi[best_result_index]\n",
    "    \n",
    "    OptimalParams2 = np.append(OptimalParams2,best_parameters, axis=0)\n",
    "    OptimalScore2 = np.append(OptimalScore2,bo.yi[np.argmin(bo.yi)])\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "#Third network, four dense layers\n",
    "for i in range(0,3):\n",
    "\n",
    "    bo_rf_43 = Optimizer(\n",
    "    dimensions=dimensions_6,\n",
    "    base_estimator=RandomForestRegressor(\n",
    "        n_estimators=100, n_jobs=4, min_variance=1.0e-6\n",
    "    ),\n",
    "    n_initial_points=10,\n",
    "    acq_func='EI',   \n",
    "    )\n",
    "\n",
    "    bo = bo_rf_43\n",
    "\n",
    "    for j in range(180):\n",
    "        x = bo.ask()\n",
    "        print(x)\n",
    "        f = target_function3(x) # Other inputs are automatically set\n",
    "\n",
    "        bo.tell(x, f)\n",
    "\n",
    "        plot_convergence(bo)\n",
    "\n",
    "    best_result_index = np.argmin(bo.yi)\n",
    "    best_parameters = bo.Xi[best_result_index]\n",
    "\n",
    "    OptimalParams3 = np.append(OptimalParams3, best_parameters, axis=0)\n",
    "    OptimalScore3 = np.append(OptimalScore3,bo.yi[np.argmin(bo.yi)])\n",
    "    \n",
    "    bo.yi[np.argmin(bo.yi)] = 1\n",
    "    \n",
    "    best_result_index = np.argmin(bo.yi)\n",
    "    best_parameters = bo.Xi[best_result_index]\n",
    "    \n",
    "    OptimalParams3 = np.append(OptimalParams3,best_parameters, axis=0)\n",
    "    OptimalScore3 = np.append(OptimalScore3,bo.yi[np.argmin(bo.yi)])\n",
    "    \n",
    "    bo.yi[np.argmin(bo.yi)] = 1\n",
    "    \n",
    "    best_result_index = np.argmin(bo.yi)\n",
    "    best_parameters = bo.Xi[best_result_index]\n",
    "    \n",
    "    OptimalParams3 = np.append(OptimalParams3,best_parameters, axis=0)\n",
    "    OptimalScore3 = np.append(OptimalScore3,bo.yi[np.argmin(bo.yi)])\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "# fourth network, five dense layers\n",
    "for i in range(0,3):\n",
    "\n",
    "    bo_rf_44 = Optimizer(\n",
    "    dimensions=dimensions_7,\n",
    "    base_estimator=RandomForestRegressor(\n",
    "        n_estimators=100, n_jobs=4, min_variance=1.0e-6\n",
    "    ),\n",
    "    n_initial_points=10,\n",
    "    acq_func='EI',   \n",
    "    )\n",
    "\n",
    "    bo = bo_rf_44\n",
    "\n",
    "    for j in range(200):\n",
    "        x = bo.ask()\n",
    "        print(x)\n",
    "        f = target_function4(x) # Other inputs are automatically set\n",
    "\n",
    "        bo.tell(x, f)\n",
    "\n",
    "        plot_convergence(bo)\n",
    "\n",
    "    best_result_index = np.argmin(bo.yi)\n",
    "    best_parameters = bo.Xi[best_result_index]\n",
    "\n",
    "    OptimalParams4 = np.append(OptimalParams4, best_parameters, axis = 0)\n",
    "    OptimalScore4 = np.append(OptimalScore4,bo.yi[np.argmin(bo.yi)])\n",
    "    \n",
    "    bo.yi[np.argmin(bo.yi)] = 1\n",
    "    \n",
    "    best_result_index = np.argmin(bo.yi)\n",
    "    best_parameters = bo.Xi[best_result_index]\n",
    "    \n",
    "    OptimalParams4 = np.append(OptimalParams4,best_parameters, axis=0)\n",
    "    OptimalScore4 = np.append(OptimalScore4,bo.yi[np.argmin(bo.yi)])\n",
    "    \n",
    "    bo.yi[np.argmin(bo.yi)] = 1\n",
    "    \n",
    "    best_result_index = np.argmin(bo.yi)\n",
    "    best_parameters = bo.Xi[best_result_index]\n",
    "    \n",
    "    OptimalParams4 = np.append(OptimalParams4,best_parameters, axis=0)\n",
    "    OptimalScore4 = np.append(OptimalScore4,bo.yi[np.argmin(bo.yi)])\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "# fifth network, No batch normalization\n",
    "for i in range(0,3):        \n",
    "\n",
    "    bo_rf_41 = Optimizer(\n",
    "    dimensions=dimensions_4,\n",
    "    base_estimator=RandomForestRegressor(\n",
    "        n_estimators=100, n_jobs=4, min_variance=1.0e-6),\n",
    "    n_initial_points=10,\n",
    "    acq_func='EI',   \n",
    "    )\n",
    "\n",
    "    bo = bo_rf_41\n",
    "\n",
    "    for j in range(100):\n",
    "        x = bo.ask()\n",
    "        print(x)\n",
    "        f = target_function_NoBatch(x) # Other inputs are automatically set\n",
    "\n",
    "        bo.tell(x, f)\n",
    "\n",
    "        plot_convergence(bo)\n",
    "\n",
    "    best_result_index = np.argmin(bo.yi)\n",
    "    best_parameters = bo.Xi[best_result_index]\n",
    "\n",
    "    OptimalParams_NoBatch = np.append(OptimalParams_NoBatch, best_parameters, axis=0)\n",
    "    OptimalScore_NoBatch = np.append(OptimalScore_NoBatch,bo.yi[np.argmin(bo.yi)])\n",
    "    \n",
    "    bo.yi[np.argmin(bo.yi)] = 1\n",
    "    \n",
    "    best_result_index = np.argmin(bo.yi)\n",
    "    best_parameters = bo.Xi[best_result_index]\n",
    "    \n",
    "    OptimalParams_NoBatch = np.append(OptimalParams_NoBatch, best_parameters, axis=0)\n",
    "    OptimalScore_NoBatch = np.append(OptimalScore_NoBatch,bo.yi[np.argmin(bo.yi)])\n",
    "    \n",
    "    bo.yi[np.argmin(bo.yi)] = 1\n",
    "    \n",
    "    best_result_index = np.argmin(bo.yi)\n",
    "    best_parameters = bo.Xi[best_result_index]\n",
    "    \n",
    "    OptimalParams_NoBatch = np.append(OptimalParams_NoBatch,best_parameters, axis=0)\n",
    "    OptimalScore_NoBatch = np.append(OptimalScore_NoBatch,bo.yi[np.argmin(bo.yi)])\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.18864702e+02, 1.93413741e+02, 1.69389836e+02, 4.89901119e-03,\n",
       "       4.75497467e-04, 2.17454314e+02, 2.45456415e+02, 1.21090369e+02,\n",
       "       7.89045064e-03, 1.98599347e-04, 2.29520992e+02, 2.52662374e+02,\n",
       "       7.24999724e+01, 7.02080878e-03, 2.58987840e-02, 2.03231592e+02,\n",
       "       1.50161741e+02, 3.57886484e+01, 7.54340476e-03, 2.87772593e-02,\n",
       "       1.95569970e+02, 1.98146921e+02, 8.71746696e+01, 8.78714283e-03,\n",
       "       2.18559220e-02, 1.95406677e+02, 7.52775069e+00, 1.88274985e+02,\n",
       "       9.91639238e-03, 2.02738047e-02, 2.52549118e+02, 5.84586671e+01,\n",
       "       2.79810692e+02, 7.70226925e-03, 1.61289666e-02, 1.26091507e+02,\n",
       "       8.93294680e+01, 2.54268985e+02, 8.12768153e-03, 6.91654171e-02,\n",
       "       1.90118898e+02, 1.22768945e+01, 2.60820247e+01, 8.69664986e-03,\n",
       "       3.23522933e-02])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OptimalParams2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResultsDict = {}\n",
    "ResultsDict = {\n",
    "    \n",
    "                'First Network' : \n",
    "               \n",
    "               { \n",
    "                 1 : {'Optimal Parameters' : OptimalParams1[0:12].tolist(), 'Optimal Score' : OptimalScore1[0:3].tolist()}, \n",
    "                 2 : {'Optimal Parameters' : OptimalParams1[12:24].tolist(), 'Optimal Score' : OptimalScore1[3:6].tolist()},\n",
    "                 3 : {'Optimal Parameters' : OptimalParams1[24:36].tolist(), 'Optimal Score' : OptimalScore1[6:9].tolist()}\n",
    "               },\n",
    "               \n",
    "                'Second Network': \n",
    "               \n",
    "               {\n",
    "                 1 : {'Optimal Parameters' : OptimalParams2[0:15].tolist(), 'Optimal Score' : OptimalScore2[0:3].tolist()}, \n",
    "                 2 : {'Optimal Parameters' : OptimalParams2[15:30].tolist(), 'Optimal Score' : OptimalScore2[3:6].tolist()},\n",
    "                 3 : {'Optimal Parameters' : OptimalParams2[30:45].tolist(), 'Optimal Score' : OptimalScore2[6:9].tolist()}\n",
    "               },\n",
    "    \n",
    "                'Third Network':\n",
    "    \n",
    "               {\n",
    "                 1 : {'Optimal Parameters' : OptimalParams3[0:18].tolist(), 'Optimal Score' : OptimalScore3[0:3].tolist()}, \n",
    "                 2 : {'Optimal Parameters' : OptimalParams3[18:36].tolist(), 'Optimal Score' : OptimalScore3[3:6].tolist()},\n",
    "                 3 : {'Optimal Parameters' : OptimalParams3[36:54].tolist(), 'Optimal Score' : OptimalScore3[6:9].tolist()}\n",
    "               },\n",
    "                \n",
    "                'Fourth Network':\n",
    "    \n",
    "               {\n",
    "                 1 : {'Optimal Parameters' : OptimalParams4[0:21].tolist(), 'Optimal Score' : OptimalScore4[0:3].tolist()}, \n",
    "                 2 : {'Optimal Parameters' : OptimalParams4[21:42].tolist(), 'Optimal Score' : OptimalScore4[3:6].tolist()},\n",
    "                 3 : {'Optimal Parameters' : OptimalParams4[42:61].tolist(), 'Optimal Score' : OptimalScore4[6:9].tolist()}\n",
    "               },\n",
    "    \n",
    "                'No Batch Network':\n",
    "    \n",
    "               {\n",
    "                 1 : {'Optimal Parameters' : OptimalParams_NoBatch[0:12].tolist(), 'Optimal Score' : OptimalScore_NoBatch[0:3].tolist()}, \n",
    "                 2 : {'Optimal Parameters' : OptimalParams_NoBatch[12:24].tolist(), 'Optimal Score' : OptimalScore_NoBatch[3:6].tolist()},\n",
    "                 3 : {'Optimal Parameters' : OptimalParams_NoBatch[24:36].tolist(), 'Optimal Score' : OptimalScore_NoBatch[6:9].tolist()}\n",
    "               }\n",
    "    \n",
    "               \n",
    "              }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'First Network': {1: {'Optimal Parameters': [143.34642200432822,\n",
       "    131.96813983771438,\n",
       "    0.007174390867507205,\n",
       "    0.0015448918050414708,\n",
       "    198.3924233618323,\n",
       "    297.9232168029428,\n",
       "    0.007801482630416755,\n",
       "    0.06662902909584964,\n",
       "    98.16494516810752,\n",
       "    14.202503608951396,\n",
       "    0.007160021442941561,\n",
       "    0.003514841233384059],\n",
       "   'Optimal Score': [0.5636999845489836,\n",
       "    0.5754790682183295,\n",
       "    0.5776988793910585]},\n",
       "  2: {'Optimal Parameters': [183.03214133090202,\n",
       "    121.38054493411309,\n",
       "    0.00997486989750012,\n",
       "    0.037232122966179,\n",
       "    182.98290987592586,\n",
       "    76.02833662794394,\n",
       "    0.009637258870804745,\n",
       "    0.05527984826977263,\n",
       "    182.997711061559,\n",
       "    83.85173990935756,\n",
       "    0.003434525525972969,\n",
       "    0.057042667398588855],\n",
       "   'Optimal Score': [0.5625060860537208,\n",
       "    0.5666069302585266,\n",
       "    0.5680965060262047]},\n",
       "  3: {'Optimal Parameters': [283.782843456031,\n",
       "    25.82482582363449,\n",
       "    0.0048377559374729795,\n",
       "    0.07748374917689638,\n",
       "    284.9846638526855,\n",
       "    123.22556910915861,\n",
       "    0.004839427337398802,\n",
       "    0.05982455324282469,\n",
       "    254.91075230970694,\n",
       "    25.768421577791294,\n",
       "    0.004891801439439815,\n",
       "    0.06466796649056859],\n",
       "   'Optimal Score': [0.5673737480482789,\n",
       "    0.5715403333871323,\n",
       "    0.5738244557129403]}},\n",
       " 'Second Network': {1: {'Optimal Parameters': [218.86470186410014,\n",
       "    193.4137406667554,\n",
       "    169.38983556908474,\n",
       "    0.004899011190318833,\n",
       "    0.0004754974666757229,\n",
       "    217.4543144247707,\n",
       "    245.45641514006002,\n",
       "    121.0903685509433,\n",
       "    0.007890450637193049,\n",
       "    0.00019859934740866785,\n",
       "    229.52099242999347,\n",
       "    252.6623737070495,\n",
       "    72.49997241226806,\n",
       "    0.007020808778246662,\n",
       "    0.025898783976793543],\n",
       "   'Optimal Score': [0.568384513156982,\n",
       "    0.5741745864139666,\n",
       "    0.5778732350438455]},\n",
       "  2: {'Optimal Parameters': [203.23159194944853,\n",
       "    150.16174073825584,\n",
       "    35.788648397245694,\n",
       "    0.007543404757567185,\n",
       "    0.028777259311852238,\n",
       "    195.56997044573583,\n",
       "    198.14692087721454,\n",
       "    87.17466961856174,\n",
       "    0.008787142827221418,\n",
       "    0.02185592203807786,\n",
       "    195.406676539786,\n",
       "    7.527750689236452,\n",
       "    188.27498536956324,\n",
       "    0.00991639237938526,\n",
       "    0.02027380465317567],\n",
       "   'Optimal Score': [0.5674611121083131,\n",
       "    0.5684579232211997,\n",
       "    0.5706082344731828]},\n",
       "  3: {'Optimal Parameters': [252.54911813640607,\n",
       "    58.45866710980132,\n",
       "    279.81069242730047,\n",
       "    0.007702269254225706,\n",
       "    0.01612896655716878,\n",
       "    126.09150747704716,\n",
       "    89.32946801703261,\n",
       "    254.26898455899916,\n",
       "    0.00812768153439251,\n",
       "    0.06916541712377415,\n",
       "    190.1188980684698,\n",
       "    12.276894513556273,\n",
       "    26.082024659353504,\n",
       "    0.008696649863015398,\n",
       "    0.03235229330696148],\n",
       "   'Optimal Score': [0.5655483523618501,\n",
       "    0.5657372961297926,\n",
       "    0.5741370171492743]}},\n",
       " 'Third Network': {1: {'Optimal Parameters': [294.36800517845126,\n",
       "    146.89851537788041,\n",
       "    236.36643912999793,\n",
       "    124.86907574325467,\n",
       "    0.0076792509108031615,\n",
       "    0.07936865543669291,\n",
       "    211.86034930967233,\n",
       "    202.80238542977088,\n",
       "    48.12820866959106,\n",
       "    68.11876323627081,\n",
       "    0.009212157089887775,\n",
       "    0.08900284425303154,\n",
       "    292.2465816519482,\n",
       "    159.71259830903745,\n",
       "    118.44347139286721,\n",
       "    108.8164483362097,\n",
       "    0.007827121197560688,\n",
       "    0.08403256311837387],\n",
       "   'Optimal Score': [0.5494096531423202,\n",
       "    0.5658099453815779,\n",
       "    0.566211209025759]},\n",
       "  2: {'Optimal Parameters': [164.97761380490044,\n",
       "    159.3497034758907,\n",
       "    193.29009513759766,\n",
       "    15.614514118433334,\n",
       "    0.009581602249499348,\n",
       "    0.004529372702113877,\n",
       "    23.4705029405123,\n",
       "    10.372165216316038,\n",
       "    115.8240916202257,\n",
       "    298.8501449840256,\n",
       "    0.009233754689874632,\n",
       "    0.03702561701457284,\n",
       "    61.17408289664597,\n",
       "    13.811052376437416,\n",
       "    112.03822694293443,\n",
       "    220.62194043076303,\n",
       "    0.009157349544703718,\n",
       "    0.09098274064291399],\n",
       "   'Optimal Score': [0.5211709984280452,\n",
       "    0.5655490441434456,\n",
       "    0.5714412181084265]},\n",
       "  3: {'Optimal Parameters': [12.2719434870387,\n",
       "    196.669774736914,\n",
       "    195.22276565323986,\n",
       "    248.30535861238252,\n",
       "    0.009531008231592066,\n",
       "    0.0039558135244552655,\n",
       "    68.67859447163896,\n",
       "    167.70168661492616,\n",
       "    292.45005279618346,\n",
       "    248.10608268950733,\n",
       "    0.008983089867547894,\n",
       "    0.025002821929707434,\n",
       "    12.399646937426953,\n",
       "    264.94450238392517,\n",
       "    116.176512875546,\n",
       "    244.98680628919027,\n",
       "    0.009607082587232266,\n",
       "    0.003264685251534783],\n",
       "   'Optimal Score': [0.5585869829567278,\n",
       "    0.5723937297852969,\n",
       "    0.5728079316635841]}},\n",
       " 'Fourth Network': {1: {'Optimal Parameters': [227.85591030008752,\n",
       "    130.85063075625396,\n",
       "    64.02010163846037,\n",
       "    6.010490568846338,\n",
       "    271.47503452934546,\n",
       "    0.006121554151067918,\n",
       "    0.06750249477687116,\n",
       "    4.171726483743031,\n",
       "    243.76659195484527,\n",
       "    179.47973654822033,\n",
       "    4.695747800226185,\n",
       "    167.92424025468722,\n",
       "    0.008804965397060665,\n",
       "    0.03799044789380478,\n",
       "    295.68359773715736,\n",
       "    228.00553847002556,\n",
       "    102.4509640767403,\n",
       "    9.264564155584445,\n",
       "    169.07238385180895,\n",
       "    0.008326470647726951,\n",
       "    0.05032862086170078],\n",
       "   'Optimal Score': [0.5706380211382316,\n",
       "    0.5717250387084576,\n",
       "    0.5723737916529693]},\n",
       "  2: {'Optimal Parameters': [114.28501759643747,\n",
       "    48.00215527818957,\n",
       "    149.74118796275718,\n",
       "    123.21313117555354,\n",
       "    106.45380180340753,\n",
       "    0.007458774604263018,\n",
       "    0.03938952494088916,\n",
       "    205.37693946135337,\n",
       "    33.57203104098865,\n",
       "    126.26559798762118,\n",
       "    255.62395581582842,\n",
       "    47.689422548902044,\n",
       "    0.00729121361584087,\n",
       "    0.034551819070074416,\n",
       "    182.8474913186681,\n",
       "    27.758127915989668,\n",
       "    115.70193299593487,\n",
       "    297.30011928608303,\n",
       "    263.96638019820267,\n",
       "    0.0067923296130299165,\n",
       "    0.07893986744219285],\n",
       "   'Optimal Score': [0.5451467995999276,\n",
       "    0.5574628001737283,\n",
       "    0.5654796445398864]},\n",
       "  3: {'Optimal Parameters': [296.35247601575173,\n",
       "    215.93340267270418,\n",
       "    56.11112979262751,\n",
       "    45.4643583382319,\n",
       "    99.99649557756435,\n",
       "    0.007714291658054555,\n",
       "    0.0501453581478468,\n",
       "    93.33119880768649,\n",
       "    131.08521213931454,\n",
       "    269.73536151052514,\n",
       "    54.74066425087253,\n",
       "    18.229491773687815,\n",
       "    0.009861080684231742,\n",
       "    0.06335638126499507,\n",
       "    91.36195991153532,\n",
       "    246.4950918317193,\n",
       "    186.0660372203964,\n",
       "    62.121394312767585,\n",
       "    164.15921384894975],\n",
       "   'Optimal Score': [0.552896330264802,\n",
       "    0.5556444417509752,\n",
       "    0.5647904517377946]}},\n",
       " 'No Batch Network': {1: {'Optimal Parameters': [107.96175174513546,\n",
       "    60.18990409536922,\n",
       "    0.0010315204827516516,\n",
       "    0.030633966731800206,\n",
       "    15.387839081796812,\n",
       "    26.724172620448638,\n",
       "    0.0011573322131685922,\n",
       "    0.02920319696339026,\n",
       "    16.824057594337596,\n",
       "    66.06464180485526,\n",
       "    0.0021121229890895157,\n",
       "    0.08997929047836953],\n",
       "   'Optimal Score': [0.9480826535967044,\n",
       "    0.9484160001308874,\n",
       "    0.9484224306611826]},\n",
       "  2: {'Optimal Parameters': [11.840071033463184,\n",
       "    15.688930717412433,\n",
       "    0.000203177121435112,\n",
       "    0.08368158339321653,\n",
       "    11.841924511159291,\n",
       "    7.118337069431794,\n",
       "    0.0008904594159623198,\n",
       "    0.06650474754324094,\n",
       "    52.33727179692734,\n",
       "    7.117730662882945,\n",
       "    0.004862680398925706,\n",
       "    0.050496111295745605],\n",
       "   'Optimal Score': [0.9210927855545931,\n",
       "    0.931337288292157,\n",
       "    0.9393996189089875]},\n",
       "  3: {'Optimal Parameters': [46.939894818011034,\n",
       "    17.603436446686835,\n",
       "    0.00010031973406757143,\n",
       "    0.013902627018958127,\n",
       "    207.36365576040888,\n",
       "    238.7486810131842,\n",
       "    0.00010966115915317349,\n",
       "    0.08978457890886994,\n",
       "    296.92030665936636,\n",
       "    128.7084507669003,\n",
       "    0.00010732835512015123,\n",
       "    0.09078699168830094],\n",
       "   'Optimal Score': [0.9391532728502764,\n",
       "    0.9530328706311468,\n",
       "    0.9590556622864108]}}}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResultsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data.json', 'w') as fp:\n",
    "    json.dump(ResultsDict, fp, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[143.34642200432822,\n",
       " 131.96813983771438,\n",
       " 0.007174390867507205,\n",
       " 0.0015448918050414708,\n",
       " 198.3924233618323,\n",
       " 297.9232168029428,\n",
       " 0.007801482630416755,\n",
       " 0.06662902909584964,\n",
       " 98.16494516810752,\n",
       " 14.202503608951396,\n",
       " 0.007160021442941561,\n",
       " 0.003514841233384059,\n",
       " 183.03214133090202,\n",
       " 121.38054493411309,\n",
       " 0.00997486989750012,\n",
       " 0.037232122966179,\n",
       " 182.98290987592586,\n",
       " 76.02833662794394,\n",
       " 0.009637258870804745,\n",
       " 0.05527984826977263,\n",
       " 182.997711061559,\n",
       " 83.85173990935756,\n",
       " 0.003434525525972969,\n",
       " 0.057042667398588855,\n",
       " 283.782843456031,\n",
       " 25.82482582363449,\n",
       " 0.0048377559374729795,\n",
       " 0.07748374917689638,\n",
       " 284.9846638526855,\n",
       " 123.22556910915861,\n",
       " 0.004839427337398802,\n",
       " 0.05982455324282469,\n",
       " 254.91075230970694,\n",
       " 25.768421577791294,\n",
       " 0.004891801439439815,\n",
       " 0.06466796649056859]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OptimalParams1.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-c8bc0cf946d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mFirst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mResultsDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"First Network\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Optimal Score\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mFirst\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mFirst\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "First = []\n",
    "for i in range(1,4):\n",
    "    First = ResultsDict[\"First Network\"][i][\"Optimal Score\"]\n",
    "    First = sum(First / 3\n",
    "    \n",
    "\n",
    "First = sum(First)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5625060860537208, 0.5666069302585266, 0.5680965060262047]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResultsDict[\"First Network\"][2][\"Optimal Score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5414268371482693"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bo.yi[np.argmin(bo.yi)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[173.2773707552993,\n",
       " 14.45812940532587,\n",
       " 0.007589349274725483,\n",
       " 0.008446173333937724]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_result_index = np.argmin(bo.yi)\n",
    "best_parameters = bo.Xi[best_result_index]\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.53841483])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(OptimalScore1,bo.yi[np.argmin(bo.yi)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5900488114779627"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_result_index = np.argmin(bo.yi)\n",
    "best_parameters = bo.Xi[best_result_index]\n",
    "\n",
    "best_result_index\n",
    "best_parameters\n",
    "bo.yi[np.argmin(bo.yi)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Gaussian optimizer ###\n",
    "\n",
    "bo_gp_1 = Optimizer(\n",
    "    ### telling optimizer boundaries for each parameter\n",
    "    dimensions=dimensions_1,\n",
    "    \n",
    "    ### setting regressor\n",
    "    base_estimator=GaussianProcessRegressor(\n",
    "        kernel=RBF(length_scale_bounds=[1.0e-6, 1.0e+6]) + \\\n",
    "            WhiteKernel(noise_level=1.0e-5, noise_level_bounds=[1.0e-6, 1.0e-2]),\n",
    "    ),\n",
    "    n_initial_points=2,\n",
    "    acq_func='EI',   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Actual optimization process ###\n",
    "def Optimization(bo,target_function):\n",
    "    Parameter_List = ([])\n",
    "    for i in range(1):\n",
    "        x = bo.ask()\n",
    "        print(x)\n",
    "        f = target_function(x) # Other inputs are automatically set\n",
    "\n",
    "        Parameter_List = np.append(Parameter_List, x)\n",
    "        bo.tell(x, f)\n",
    "\n",
    "        plot_convergence(bo)\n",
    "        \n",
    "        best_result_index = np.argmin(bo.yi)\n",
    "        best_parameters = bo.Xi[best_result_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model:\n",
      " Nodes in first dense layer= 235 \n",
      " Nodes in second dense layer= 147 \n",
      " learning rate= 0.02177968898175681 \n",
      " Dropout value= 0.005580370632707155\n"
     ]
    }
   ],
   "source": [
    "print_best(bo_rf_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 271)               17886     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 271)               1084      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 271)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 280)               76160     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 562       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 95,692\n",
      "Trainable params: 95,150\n",
      "Non-trainable params: 542\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 43565 samples, validate on 10892 samples\n",
      "Epoch 1/3\n",
      "43565/43565 [==============================] - 14s 321us/step - loss: 0.2786 - acc: 0.9236 - val_loss: 0.2719 - val_acc: 0.9250\n",
      "Epoch 2/3\n",
      "43565/43565 [==============================] - 12s 265us/step - loss: 0.2433 - acc: 0.9250 - val_loss: 0.2521 - val_acc: 0.9247\n",
      "Epoch 3/3\n",
      "43565/43565 [==============================] - 11s 249us/step - loss: 0.2363 - acc: 0.9251 - val_loss: 0.2567 - val_acc: 0.9266\n",
      "0.3481612531447594\n",
      "Train on 43565 samples, validate on 10892 samples\n",
      "Epoch 1/3\n",
      "43565/43565 [==============================] - 11s 260us/step - loss: 0.2347 - acc: 0.9254 - val_loss: 0.2492 - val_acc: 0.9261\n",
      "Epoch 2/3\n",
      "43565/43565 [==============================] - 12s 266us/step - loss: 0.2334 - acc: 0.9253 - val_loss: 0.2366 - val_acc: 0.9262\n",
      "Epoch 3/3\n",
      "43565/43565 [==============================] - 11s 243us/step - loss: 0.2326 - acc: 0.9258 - val_loss: 0.2347 - val_acc: 0.9266\n",
      "0.3777592072609885\n",
      "Train on 43565 samples, validate on 10892 samples\n",
      "Epoch 1/3\n",
      "43565/43565 [==============================] - 11s 246us/step - loss: 0.2322 - acc: 0.9259 - val_loss: 0.2292 - val_acc: 0.9276\n",
      "Epoch 2/3\n",
      "43565/43565 [==============================] - 12s 278us/step - loss: 0.2303 - acc: 0.9265 - val_loss: 0.2333 - val_acc: 0.9264\n",
      "Epoch 3/3\n",
      "43565/43565 [==============================] - 11s 245us/step - loss: 0.2311 - acc: 0.9263 - val_loss: 0.2338 - val_acc: 0.9273\n",
      "0.3755042846797935\n",
      "Train on 43565 samples, validate on 10892 samples\n",
      "Epoch 1/3\n",
      "43565/43565 [==============================] - 11s 261us/step - loss: 0.2310 - acc: 0.9257 - val_loss: 0.2362 - val_acc: 0.9255\n",
      "Epoch 2/3\n",
      "43565/43565 [==============================] - 12s 268us/step - loss: 0.2297 - acc: 0.9270 - val_loss: 0.2340 - val_acc: 0.9248\n",
      "Epoch 3/3\n",
      "43565/43565 [==============================] - 11s 248us/step - loss: 0.2309 - acc: 0.9260 - val_loss: 0.2338 - val_acc: 0.9249\n",
      "0.4127228370619375\n",
      "Train on 43565 samples, validate on 10892 samples\n",
      "Epoch 1/3\n",
      "43565/43565 [==============================] - 11s 262us/step - loss: 0.2295 - acc: 0.9256 - val_loss: 0.2429 - val_acc: 0.9262\n",
      "Epoch 2/3\n",
      "43565/43565 [==============================] - 11s 253us/step - loss: 0.2300 - acc: 0.9252 - val_loss: 0.2349 - val_acc: 0.9266\n",
      "Epoch 3/3\n",
      "43565/43565 [==============================] - 12s 268us/step - loss: 0.2312 - acc: 0.9258 - val_loss: 0.2394 - val_acc: 0.9265\n",
      "0.3827155505030586\n"
     ]
    }
   ],
   "source": [
    "### Testing the found parameters to see if the results are reproduceable ###\n",
    "\n",
    "INIT_LEARNINGRATE = 0.02532767329545395  \n",
    "BATCH_SIZE = 16  # should be a factor of len(x_train) and len(x_val) etc.\n",
    "EPOCHS = 3\n",
    "\n",
    "assert len(y_train) == len(x_train), \"x_train and y_train not same length!\"\n",
    "#assert len(y_train) % BATCH_SIZE == 0, \"batch size should be multiple of training size,{0}/{1}\".format(len(y_train),BATCH_SIZE)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(271, activation='relu', input_shape=( len( utils.SIMPLE_FEATURE_COLUMNS ), ))) #length = input vars\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.0009682674694188368))\n",
    "model.add(Dense(280, activation='relu'))\n",
    "model.add(Dense( len(classes) )) # muon and 'other'\n",
    "model.add(Activation(\"softmax\")) # output probabilities\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.adamax(lr=INIT_LEARNINGRATE),\n",
    "    metrics=['accuracy'] \n",
    "    )\n",
    "\n",
    "# Running test for 5 times in this case\n",
    "for i in range(0,5):\n",
    "    model.fit(\n",
    "        x_train, y_train,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        epochs = EPOCHS,\n",
    "        validation_data = (x_val, y_val),\n",
    "        shuffle = True\n",
    "        )\n",
    "\n",
    "\n",
    "    #model.save_model(\"keras_basic_model.xgb\")\n",
    "\n",
    "\n",
    "    # score\n",
    "\n",
    "    validation_predictions = model.predict_proba(val_part.loc[:, utils.SIMPLE_FEATURE_COLUMNS].values)[:, 1]\n",
    "    result = scoring.rejection90(val_part.label.values, validation_predictions, sample_weight=val_part.weight.values)\n",
    "    print(result)\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               6600      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 102       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 12,152\n",
      "Trainable params: 11,952\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 43565 samples, validate on 10892 samples\n",
      "Epoch 1/3\n",
      "43565/43565 [==============================] - 8s 176us/step - loss: 0.2471 - acc: 0.9252 - val_loss: 0.2437 - val_acc: 0.9234\n",
      "Epoch 2/3\n",
      "43565/43565 [==============================] - 6s 143us/step - loss: 0.2357 - acc: 0.9267 - val_loss: 0.2456 - val_acc: 0.9224\n",
      "Epoch 3/3\n",
      "43565/43565 [==============================] - 6s 141us/step - loss: 0.2323 - acc: 0.9263 - val_loss: 0.2408 - val_acc: 0.9236\n",
      "0.3487180061696864\n"
     ]
    }
   ],
   "source": [
    "#### Original keras model for reference ####\n",
    "\n",
    "INIT_LEARNINGRATE = 5e-3\n",
    "BATCH_SIZE = 16  # should be a factor of len(x_train) and len(x_val) etc.\n",
    "EPOCHS = 3\n",
    "\n",
    "assert len(y_train) == len(x_train), \"x_train and y_train not same length!\"\n",
    "#assert len(y_train) % BATCH_SIZE == 0, \"batch size should be multiple of training size,{0}/{1}\".format(len(y_train),BATCH_SIZE)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape=( len( utils.SIMPLE_FEATURE_COLUMNS ), ))) #length = input vars\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(50 , activation='relu'))\n",
    "model.add(Dense( len(classes) )) # muon and 'other'\n",
    "model.add(Activation(\"softmax\")) # output probabilities\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.adamax(lr=INIT_LEARNINGRATE),\n",
    "    metrics=['accuracy'] \n",
    "    )\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    epochs = EPOCHS,\n",
    "    validation_data = (x_val, y_val),\n",
    "    shuffle = True\n",
    "    )\n",
    "\n",
    "#model.save_model(\"keras_basic_model.xgb\")\n",
    "\n",
    "\n",
    "# score\n",
    "\n",
    "validation_predictions = model.predict_proba(val_part.loc[:, utils.SIMPLE_FEATURE_COLUMNS].values)[:, 1]\n",
    "result = scoring.rejection90(val_part.label.values, validation_predictions, sample_weight=val_part.weight.values)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    \n",
    "    for j in range(0,5):\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nproc' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!nproc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = multiprocessing.Pool(processes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_1_input to have shape (65,) but got array with shape (2,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\miniconda\\envs\\py36\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"c:\\miniconda\\envs\\py36\\lib\\multiprocessing\\pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"c:\\miniconda\\envs\\py36\\lib\\site-packages\\keras\\engine\\training.py\", line 952, in fit\n    batch_size=batch_size)\n  File \"c:\\miniconda\\envs\\py36\\lib\\site-packages\\keras\\engine\\training.py\", line 751, in _standardize_user_data\n    exception_prefix='input')\n  File \"c:\\miniconda\\envs\\py36\\lib\\site-packages\\keras\\engine\\training_utils.py\", line 138, in standardize_input_data\n    str(data_shape))\nValueError: Error when checking input: expected dense_1_input to have shape (65,) but got array with shape (2,)\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-f031f348a31a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\miniconda\\envs\\py36\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         '''\n\u001b[1;32m--> 288\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\miniconda\\envs\\py36\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    668\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 670\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    671\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected dense_1_input to have shape (65,) but got array with shape (2,)"
     ]
    }
   ],
   "source": [
    "r = pool.map(model.fit, [x_train, y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataDict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-b07ee00383a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mDataDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'FirstNetwork'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'run {0}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'DataDict' is not defined"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "DataDict['FirstNetwork']['run {0}'.format(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
