{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import utils\n",
    "import scoring\n",
    "import numpy as np\n",
    "\n",
    "from skopt import Optimizer\n",
    "\n",
    "from skopt.learning import GaussianProcessRegressor\n",
    "from skopt.learning.gaussian_process.kernels import Matern, RBF, WhiteKernel\n",
    "\n",
    "from skopt.learning import RandomForestRegressor\n",
    "\n",
    "from skopt.acquisition import gaussian_ei as acq_func\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing and structuring data ###\n",
    "\n",
    "DATA_PATH = \"./data/\"\n",
    "train, test = utils.load_small_data_csv(DATA_PATH,\"train_smaller100.csv.gz\" , \"test_smaller100.csv.gz\", utils.SIMPLE_FEATURE_COLUMNS)\n",
    "\n",
    "PointResiduals,Angles = utils.kink(train)\n",
    "train['PointResiduals'] = pd.Series(PointResiduals, index=train.index)\n",
    "train['Angles'] = pd.Series(PointResiduals, index=train.index)\n",
    "\n",
    "\n",
    "train_part, val_part = train_test_split(train, test_size=0.20, shuffle=True)\n",
    "x_train = train_part.loc[:, utils.SIMPLE_FEATURE_COLUMNS].values\n",
    "x_val   =  val_part.loc[:, utils.SIMPLE_FEATURE_COLUMNS].values\n",
    "y_train = train_part.loc[:, [\"label\"]].values\n",
    "y_val = val_part.loc[:, [\"label\"]].values\n",
    "#y_train_weight = train_part.loc[:, [\"weight\"]].values\n",
    "\n",
    "# turn labels into categorical classes\n",
    "classes = [0,1]\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=len(classes))\n",
    "y_val   = keras.utils.to_categorical(y_val,   num_classes=len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining utils ###\n",
    "\n",
    "# Rectified linear unit\n",
    "\n",
    "def relu(x):\n",
    "  return np.array([ (i>0) * abs(i) for i in x ])\n",
    "\n",
    "# plotting the bayesian optimizer\n",
    "\n",
    "def plot_bo(bo, suggestion=None, value=None):\n",
    "    a, b = bo.space.bounds[0]\n",
    "    \n",
    "    # getting the latest model\n",
    "    model = bo.models[-1]\n",
    "    \n",
    "    xs = np.linspace(a, b, num=100)\n",
    "    x_model = bo.space.transform(xs.reshape(-1, 1).tolist())\n",
    "    \n",
    "    mean, std = model.predict(x_model, return_std=True)\n",
    "    \n",
    "    plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(\n",
    "        np.array(bo.Xi)[:, 0],\n",
    "        np.array(bo.yi),\n",
    "        color='red',\n",
    "        label='observations'\n",
    "    )\n",
    "    if suggestion is not None:\n",
    "        plt.scatter([suggestion], value, color='blue', label='suggestion')\n",
    "    \n",
    "    plt.plot(xs, mean, color='green', label='model')\n",
    "    plt.fill_between(xs, mean - 1.96 * std, mean + 1.96 * std, alpha=0.1, color='green')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    acq = acq_func(x_model, model, np.min(bo.yi))\n",
    "    plt.plot(xs, acq, label='Expected Improvement')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# \n",
    "\n",
    "def cum_min(xs):\n",
    "    result = np.zeros_like(xs)\n",
    "    cmin = xs[0]\n",
    "    \n",
    "    result[0] = xs[0]\n",
    "    \n",
    "    for i in range(1, xs.shape[0]):\n",
    "        if cmin > xs[i]:\n",
    "            cmin = xs[i]\n",
    "\n",
    "        result[i] = cmin\n",
    "    \n",
    "    return result\n",
    "\n",
    "# plots progress of BO over time\n",
    "\n",
    "def plot_convergence(bo):\n",
    "    display.clear_output(wait=True)\n",
    "    values = np.array(bo.yi)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(cum_min(values), label='minimal discovered')\n",
    "    plt.scatter(np.arange(len(bo.yi)), bo.yi, label='observations')\n",
    "    plt.xlabel('step', fontsize=14)\n",
    "    plt.ylabel('loss', fontsize=14)\n",
    "    \n",
    "    plt.legend(loc='upper right', fontsize=18)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Prints best parameters\n",
    "    \n",
    "def print_best(bo):\n",
    "    best_result_index = np.argmin(bo.yi)\n",
    "    best_parameters = bo.Xi[best_result_index]\n",
    "\n",
    "    NodesInFirstDense, NodesInSecondDense, DropoutValue, INIT_LEARNINGRATE = best_parameters\n",
    "    \n",
    "    print(\n",
    "        'Best model:\\n Nodes in first dense layer= {0} \\n Nodes in second dense layer= {1} \\n learning rate= {2} \\n Dropout value= {3}'.format(\n",
    "            int(np.ceil(NodesInFirstDense)),\n",
    "            int(np.ceil(NodesInSecondDense)),\n",
    "            INIT_LEARNINGRATE,\n",
    "            DropoutValue\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Target function with as input optimizeable parameters ###\n",
    "\n",
    "def target_function(params, X_train=x_train, y_train=y_train, X_score=x_val, y_score=y_val):\n",
    "    \n",
    "    # Optimized parameters\n",
    "    NodesInFirstDense, NodesInSecondDense, DropoutValue, INIT_LEARNINGRATE = params\n",
    "    \n",
    "    # Making sure that the number of nodes are integers\n",
    "    NodesInFirstDense = int(np.ceil(NodesInFirstDense))\n",
    "    NodesInSecondDense = int(np.ceil(NodesInSecondDense))\n",
    "    \n",
    "    # Two parameters not optimized in this case, but can be optimized if needed\n",
    "    BATCH_SIZE = 16  # should be a factor of len(x_train) and len(x_val) etc.\n",
    "    EPOCHS = 3\n",
    "\n",
    "    assert len(y_train) == len(x_train), \"x_train and y_train not same length!\"\n",
    "    #assert len(y_train) % BATCH_SIZE == 0, \"batch size should be multiple of training size,{0}/{1}\".format(len(y_train),BATCH_SIZE)\n",
    "\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Activation, Dropout\n",
    "    from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "    K.clear_session()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(NodesInFirstDense, activation='relu', input_shape=( len( utils.SIMPLE_FEATURE_COLUMNS ), ))) #length = input vars\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(DropoutValue))\n",
    "    model.add(Dense(NodesInSecondDense , activation='relu'))\n",
    "    model.add(Dense( len(classes) )) # muon and 'other'\n",
    "    model.add(Activation(\"softmax\")) # output probabilities\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=keras.optimizers.adamax(lr=INIT_LEARNINGRATE),\n",
    "        metrics=['accuracy'] \n",
    "        )\n",
    "\n",
    "\n",
    "    model.fit(\n",
    "        x_train, y_train,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        epochs = EPOCHS,\n",
    "        validation_data = (x_val, y_val),\n",
    "        shuffle = True\n",
    "        )\n",
    "\n",
    "    #model.save_model(\"keras_basic_model.xgb\")\n",
    "\n",
    "\n",
    "    # score\n",
    "\n",
    "    validation_predictions = model.predict_proba(val_part.loc[:, utils.SIMPLE_FEATURE_COLUMNS].values)[:, 1]\n",
    "    result = scoring.rejection90(val_part.label.values, validation_predictions, sample_weight=val_part.weight.values)\n",
    "    print(result)\n",
    "    \n",
    "    return 1 - result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting dimensions for optimizeable parameters ###\n",
    "\n",
    "dimensions_4 =[\n",
    "    # NodesInFirstDense\n",
    "    (4.0, 300.0),\n",
    "    \n",
    "    # NodesInSecondDense\n",
    "    (4.0, 300.0),\n",
    "    \n",
    "    # LOG_INIT_LEARNINGRATE\n",
    "    (1.0e-4, 1.0e-2),\n",
    "    \n",
    "    # DropoutValue\n",
    "    (0.0, 0.1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random forest regressor as optimizer ###\n",
    "\n",
    "bo_rf_4 = Optimizer(\n",
    "    dimensions=dimensions_4,\n",
    "    base_estimator=RandomForestRegressor(\n",
    "        n_estimators=100, n_jobs=4, min_variance=1.0e-6\n",
    "    ),\n",
    "    n_initial_points=5,\n",
    "    acq_func='EI',   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Actual optimization process ###\n",
    "\n",
    "Parameter_List = ([])\n",
    "for i in range(50):\n",
    "    x = bo_rf_4.ask()\n",
    "    print(x)\n",
    "    f = target_function(x) # Other inputs are automatically set\n",
    "    \n",
    "    Parameter_List = np.append(Parameter_List, x)\n",
    "    bo_rf_4.tell(x, f)\n",
    "        \n",
    "    plot_convergence(bo_rf_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model:\n",
      " Nodes in first dense layer= 271 \n",
      " Nodes in second dense layer= 280 \n",
      " learning rate= 0.02532767329545395 \n",
      " Dropout value= 0.0009682674694188368\n"
     ]
    }
   ],
   "source": [
    "print_best(bo_rf_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 271)               17886     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 271)               1084      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 271)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 280)               76160     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 562       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 95,692\n",
      "Trainable params: 95,150\n",
      "Non-trainable params: 542\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 43565 samples, validate on 10892 samples\n",
      "Epoch 1/3\n",
      "43565/43565 [==============================] - 14s 321us/step - loss: 0.2786 - acc: 0.9236 - val_loss: 0.2719 - val_acc: 0.9250\n",
      "Epoch 2/3\n",
      "43565/43565 [==============================] - 12s 265us/step - loss: 0.2433 - acc: 0.9250 - val_loss: 0.2521 - val_acc: 0.9247\n",
      "Epoch 3/3\n",
      "43565/43565 [==============================] - 11s 249us/step - loss: 0.2363 - acc: 0.9251 - val_loss: 0.2567 - val_acc: 0.9266\n",
      "0.3481612531447594\n",
      "Train on 43565 samples, validate on 10892 samples\n",
      "Epoch 1/3\n",
      "43565/43565 [==============================] - 11s 260us/step - loss: 0.2347 - acc: 0.9254 - val_loss: 0.2492 - val_acc: 0.9261\n",
      "Epoch 2/3\n",
      "43565/43565 [==============================] - 12s 266us/step - loss: 0.2334 - acc: 0.9253 - val_loss: 0.2366 - val_acc: 0.9262\n",
      "Epoch 3/3\n",
      "43565/43565 [==============================] - 11s 243us/step - loss: 0.2326 - acc: 0.9258 - val_loss: 0.2347 - val_acc: 0.9266\n",
      "0.3777592072609885\n",
      "Train on 43565 samples, validate on 10892 samples\n",
      "Epoch 1/3\n",
      "43565/43565 [==============================] - 11s 246us/step - loss: 0.2322 - acc: 0.9259 - val_loss: 0.2292 - val_acc: 0.9276\n",
      "Epoch 2/3\n",
      "43565/43565 [==============================] - 12s 278us/step - loss: 0.2303 - acc: 0.9265 - val_loss: 0.2333 - val_acc: 0.9264\n",
      "Epoch 3/3\n",
      "43565/43565 [==============================] - 11s 245us/step - loss: 0.2311 - acc: 0.9263 - val_loss: 0.2338 - val_acc: 0.9273\n",
      "0.3755042846797935\n",
      "Train on 43565 samples, validate on 10892 samples\n",
      "Epoch 1/3\n",
      "43565/43565 [==============================] - 11s 261us/step - loss: 0.2310 - acc: 0.9257 - val_loss: 0.2362 - val_acc: 0.9255\n",
      "Epoch 2/3\n",
      "43565/43565 [==============================] - 12s 268us/step - loss: 0.2297 - acc: 0.9270 - val_loss: 0.2340 - val_acc: 0.9248\n",
      "Epoch 3/3\n",
      "43565/43565 [==============================] - 11s 248us/step - loss: 0.2309 - acc: 0.9260 - val_loss: 0.2338 - val_acc: 0.9249\n",
      "0.4127228370619375\n",
      "Train on 43565 samples, validate on 10892 samples\n",
      "Epoch 1/3\n",
      "43565/43565 [==============================] - 11s 262us/step - loss: 0.2295 - acc: 0.9256 - val_loss: 0.2429 - val_acc: 0.9262\n",
      "Epoch 2/3\n",
      "43565/43565 [==============================] - 11s 253us/step - loss: 0.2300 - acc: 0.9252 - val_loss: 0.2349 - val_acc: 0.9266\n",
      "Epoch 3/3\n",
      "43565/43565 [==============================] - 12s 268us/step - loss: 0.2312 - acc: 0.9258 - val_loss: 0.2394 - val_acc: 0.9265\n",
      "0.3827155505030586\n"
     ]
    }
   ],
   "source": [
    "### Testing the found parameters to see if the results are reproduceable ###\n",
    "\n",
    "INIT_LEARNINGRATE = 0.02532767329545395  \n",
    "BATCH_SIZE = 16  # should be a factor of len(x_train) and len(x_val) etc.\n",
    "EPOCHS = 3\n",
    "\n",
    "assert len(y_train) == len(x_train), \"x_train and y_train not same length!\"\n",
    "#assert len(y_train) % BATCH_SIZE == 0, \"batch size should be multiple of training size,{0}/{1}\".format(len(y_train),BATCH_SIZE)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(271, activation='relu', input_shape=( len( utils.SIMPLE_FEATURE_COLUMNS ), ))) #length = input vars\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.0009682674694188368))\n",
    "model.add(Dense(280, activation='relu'))\n",
    "model.add(Dense( len(classes) )) # muon and 'other'\n",
    "model.add(Activation(\"softmax\")) # output probabilities\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.adamax(lr=INIT_LEARNINGRATE),\n",
    "    metrics=['accuracy'] \n",
    "    )\n",
    "\n",
    "# Running test for 5 times in this case\n",
    "for i in range(0,5):\n",
    "    model.fit(\n",
    "        x_train, y_train,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        epochs = EPOCHS,\n",
    "        validation_data = (x_val, y_val),\n",
    "        shuffle = True\n",
    "        )\n",
    "\n",
    "\n",
    "    #model.save_model(\"keras_basic_model.xgb\")\n",
    "\n",
    "\n",
    "    # score\n",
    "\n",
    "    validation_predictions = model.predict_proba(val_part.loc[:, utils.SIMPLE_FEATURE_COLUMNS].values)[:, 1]\n",
    "    result = scoring.rejection90(val_part.label.values, validation_predictions, sample_weight=val_part.weight.values)\n",
    "    print(result)\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               6600      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 102       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 12,152\n",
      "Trainable params: 11,952\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 43565 samples, validate on 10892 samples\n",
      "Epoch 1/3\n",
      "43565/43565 [==============================] - 9s 210us/step - loss: 0.2515 - acc: 0.9238 - val_loss: 0.2376 - val_acc: 0.9264\n",
      "Epoch 2/3\n",
      "43565/43565 [==============================] - 8s 189us/step - loss: 0.2381 - acc: 0.9252 - val_loss: 0.2359 - val_acc: 0.9264\n",
      "Epoch 3/3\n",
      "43565/43565 [==============================] - 8s 193us/step - loss: 0.2331 - acc: 0.9254 - val_loss: 0.2353 - val_acc: 0.9233\n",
      "0.3931053509980917\n"
     ]
    }
   ],
   "source": [
    "#### Original keras model for reference ####\n",
    "\n",
    "INIT_LEARNINGRATE = 5e-3\n",
    "BATCH_SIZE = 16  # should be a factor of len(x_train) and len(x_val) etc.\n",
    "EPOCHS = 3\n",
    "\n",
    "assert len(y_train) == len(x_train), \"x_train and y_train not same length!\"\n",
    "#assert len(y_train) % BATCH_SIZE == 0, \"batch size should be multiple of training size,{0}/{1}\".format(len(y_train),BATCH_SIZE)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape=( len( utils.SIMPLE_FEATURE_COLUMNS ), ))) #length = input vars\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(50 , activation='relu'))\n",
    "model.add(Dense( len(classes) )) # muon and 'other'\n",
    "model.add(Activation(\"softmax\")) # output probabilities\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.adamax(lr=INIT_LEARNINGRATE),\n",
    "    metrics=['accuracy'] \n",
    "    )\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    epochs = EPOCHS,\n",
    "    validation_data = (x_val, y_val),\n",
    "    shuffle = True\n",
    "    )\n",
    "\n",
    "#model.save_model(\"keras_basic_model.xgb\")\n",
    "\n",
    "\n",
    "# score\n",
    "\n",
    "validation_predictions = model.predict_proba(val_part.loc[:, utils.SIMPLE_FEATURE_COLUMNS].values)[:, 1]\n",
    "result = scoring.rejection90(val_part.label.values, validation_predictions, sample_weight=val_part.weight.values)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    \n",
    "    for i in range(0,5):\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6138837783026205,\n",
       " 0.6349518151422029,\n",
       " 0.6360014049368095,\n",
       " 0.6103059598267513,\n",
       " 1.0,\n",
       " 0.6449686461789483,\n",
       " 0.6145585949283894,\n",
       " 1.0,\n",
       " 0.6172820058660087,\n",
       " 0.6566584275598751,\n",
       " 1.0,\n",
       " 0.6220041901481674,\n",
       " 0.6264386787015994,\n",
       " 1.0,\n",
       " 0.604951611087879,\n",
       " 0.6095909838720766,\n",
       " 0.656927293426929,\n",
       " 0.608980667919611,\n",
       " 0.6527089089759961,\n",
       " 0.6279269015449258,\n",
       " 1.0,\n",
       " 0.6081045806204743,\n",
       " 0.620127324791726,\n",
       " 0.6380099990965296,\n",
       " 0.636469294134699,\n",
       " 0.5922538027108551,\n",
       " 0.6199345905937721,\n",
       " 0.6570863715698672,\n",
       " 0.56070593629403,\n",
       " 0.6273099731185394,\n",
       " 0.6194939710103458,\n",
       " 0.6431254462198318,\n",
       " 0.6023394501363204,\n",
       " 0.5944696087512363,\n",
       " 0.6524680067610242,\n",
       " 0.6554186706244411,\n",
       " 0.620954638858362,\n",
       " 0.5926848723449285,\n",
       " 0.6896124602943006,\n",
       " 0.6521048070287294,\n",
       " 0.616825635661548,\n",
       " 1.0,\n",
       " 0.6113836346199518,\n",
       " 0.6309258631930211,\n",
       " 0.6625225050987436,\n",
       " 0.6186054721300805,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.6437468909104095,\n",
       " 0.6666731793184841]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_result_index = np.argmin(bo_rf_4.yi)\n",
    "best_parameters = bo_rf_4.Xi[best_result_index]\n",
    "\n",
    "bo_rf_4.yi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
